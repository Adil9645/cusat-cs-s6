19-202-0606(IE) NEURAL NETWORKS AND DEEP LEARNING
Course Outcomes:
On completion of this course the student will be able to:
1. Identify the basic concepts of deep learning
2. Analyse the deep learning architectures which are appropriate for various types of
learning tasks in different domains
3. Illustrate use of TensorFlow libraries to implement deep neural networks
4. Apply TensorFlow in NLP applications.
Module I
Introduction to neural networks: Artificial neural networks, Biological neural networks,
McCulloch–Pitts neuron. Perceptron: architecture, algorithm, perceptron learning rule convergence
theorem.
Feedforward Networks: Multilayer Perceptron, Gradient Descent, Backpropagation.
Module II
Convolutional Neural Networks: Architectures, convolution / pooling layers.
Recurrent Neural Networks: Back propagation through time, Bidirectional RNNs ,Long Short Term
Memory, Gated Recurrent Units, Bidirectional LSTMs.
Module III
TensorFlow: Introduction, tensors, tensor properties, basic tensor methods.
CNN in TensorFlow: Applying convolution in TensorFlow, applying pool operations in TensorFlow,
Applying Dropout operation in Tensor Flow, Implementation of CNN in TensorFlow.
RNN in TensorFlow: TensorFlow LSTM useful classes and methods, Implementation of RNN in
TensorFlow.
Module IV
Applications of Deep Learning to NLP: Introduction, working with bag of words, Implementing
TF-IDF, Working with skip-gram embeddings, CBOW embeddings, making predictions with
word2vec, using doc2vec for sentiment analysis.
References:
1. Laurene Fausett, Fundamentals of Neural Networks, Prentice Hall, New Jersey, 2007.
2. Ian Goodfellow,Yoshua Bengio and Aaron Courville, Deep Learning, MIT Press, 2016.
3. Aurelien Geron, Hands-on Machine Learning with Scikit-Learn, Keras, and
TensorFlow,O’Reilly Media,2019
4. Rodolfo Bonnin, Building Machine Learning Projects with TensorFlow, Packt Publishing,
2016.
5. Nick McClure, Tensorflow Machine Learning Cookbook, Packt Publishing, 2017